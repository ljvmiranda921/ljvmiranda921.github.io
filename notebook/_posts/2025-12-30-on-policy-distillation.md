---
layout: post
type: post
title: "On-policy distillation on a budget"
date: 2025-12-30
category: notebook
comments: true
author: "LJ MIRANDA"
published: true
tags:
  [
    nlp,
    distillation,
    on-policy,
    natural language processing,
    llm,

  ]
description: |
  Just playing around on-policy distillation using quantized models using llamacpp on an M4.
  I just want to know if (a) it's doable and (b) what's the most quantized model that can produce a decent LLM.
excerpt: |
---