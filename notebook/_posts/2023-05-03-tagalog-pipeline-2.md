---
layout: post
type: post
title: "Some follow-up experiments for Tagalog NLP"
date: 2023-05-03
category: notebook
comments: true
author: "LJ MIRANDA"
published: true
tags: [nlp, tagalog, low-resource languages, prodigy, natural language processing, machine learning]
header-img: /assets/png/tagalog-gold-standard/header.png
description: |
    In this blog post, I'd like to share updates about my Tagalog NLP
    pipeline. I want to talk about training curves, in-depth dataset statistics, and
    some new components (dependency parser and part-of-speech tagger).
excerpt: |
    In this blog post, I'd like to share updates about my Tagalog NLP
    pipeline. I want to talk about training curves, in-depth dataset statistics, and
    some new components (dependency parser and part-of-speech tagger).
---

<span class="firstcharacter">F</span>irst off, I'm happy to see such warm
reception to my [first blog post](/2023/02/04/tagalog-pipeline/) about building
a Tagalog NLP pipeline. Thank you! There are a few more experiments that I
wanted to do for the sake of completeness and rigor. I hope to release the alpha
version of [calamanCy](https://github.com/ljvmiranda921/calamanCy) in August, so
this blog post may as well be a lead-up to that release. I will structure this
post into three main buckets as shown in the figure below:

![](/assets/png/tagalog-gold-standard/process.png){:width="650px"}  
{:style="text-align: center;"}

## On annotation

### How much change occured between silver to gold?

### Do I need to annotate more? 

## On building the pipeline

### What is the effect of hyperparameters? 

## On evaluation

### On which entities does the model make mistakes?


