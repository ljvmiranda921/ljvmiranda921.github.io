---
layout: post
type: post
title: "Field Report: ACL 2025"
date: 2025-08-01
category: notebook
comments: true
author: "LJ MIRANDA"
published: true
header-img: /assets/png/field-report-acl25/header.png
tags: [nlp, acl, conference, research, natural language processing, ai, llm, reasoning]
description: |
    Here is my field report from the ACL 2025 Conference in Vienna.
    I learned a lot about X, got excited about Y, and had lots of fun all throughout!
excerpt: |
---

<span class="firstcharacter">I</span> had an incredible time at the [ACL 2025 Conference](https://2025.aclweb.org/) in Vienna.
ACL is one of the top conferences in NLP, with researchers presenting a wide range of work from computational linguistics to frontier large language models.
This was also the very first NLP conference I attended.
Although I had published in *CL venues before, I never had the chance to attend in person.
Attending ACL was also a great way to immerse myself in the broader NLP community before starting my Ph.D.
<!-- pictures of vienna and the place baby! -->


## Works I presented during the conference

<!-- collage of photos of YOU with your posters! -->

Self-promotion: I had four papers accepted in the ACL Main Proceedings, three of which I was the first or co-first author on (all in the Resources & Evaluation track):

- [Hybrid Preferences: Learning to Route Instances for Human vs. AI Feedback](https://arxiv.org/abs/2410.19133)<br>TLDR: We find that some preference instances are better annotated by humans than by language models (LMs). We use that information to train a hybrid preference router (HyPER) that allocates instances to either humans or LMs.
- [M-RewardBench: Evaluating Reward Models in Multilingual Settings.](https://arxiv.org/abs/2410.15522)<br>TLDR: We introduce a new benchmark for evaluating reward models (RMs) in 23 diverse languages. By evaluating several RMs on M-RewardBench, we uncovered signficant gaps in RM performance between English and non-English languages.
- [The UD-NewsCrawl Treebank: Reflections and Challenges from a Large-scale Tagalog Syntactic Annotation Project](https://arxiv.org/abs/2505.20428)<br>TLDR: We introduce the largest Tagalog treebank to date, 100x larger than previous treebanks. 
By building this treebank, we stretch the limits of the Universal Dependencies framework and challenge its "universality."

And a big collab project from SEACrowd:

- [Crowdsource, Crawl, or Generate? Creating SEA-VL, a Multicultural Vision-Language Dataset for Southeast Asia](https://arxiv.org/abs/2503.07920)<br>TLDR: We present SEA-VL, one of the largest open-source initiatives to develop high-quality and culturally-relevant data for SEA languages. We also highlight representation gaps in SEA, especially for vision-language models.


*Really, four papers?!* This seems like a big feat, but these works were completed at different times&mdash;it's just that the timing led them to be published simultaneously.
In fact, HyPER was a reject from ICLR and my involvement in UD-NewsCrawl started way back in 2023.
Good research takes time, and I'm lucky to have great collaborators during these long periods of work.

## My favorite papers


<!-- top five papers -->

<!-- three honorable mentions??? -->


## NLP research vibes and trends



## Miscellaneous

<!-- collage of photos -->

* **I attended the SEACrowd Birds-of-a-Feather (BoF) session!** Finally, I've met my long-time collaborators.
    I've been involved with the SEACrowd group during their initial project, so it's nice to meet Holy, Samuel, Aji, and Genta in person.
    During the BoF, we talked about

* **Met with some Pinoy NLP researchers.** It is nice to meetup with some folks from the 
    Asian Institute of Management in the Philippines&mdash;they wrote an industry-track paper on examining the reliability of LLMs in clinical note generation.
    Blaise (PhD-ing in MBZUAI) and Anton (from SEACrowd) were also there.
    I also met another Ateneo org-mate, Jane, who is now doing her PhD in Radboud University in the Netherlands.
    In general, it's nice to see Filipinos publishing in these top NLP conferences.



## Final thoughts

Attending ACL 2025 is a great way to close my pre-PhD years and start my new journey as a PhD student.
As my first NLP conference, ACL gave me a favorable first impression of the community at large.
Perhaps I've been lucky with the people I've talked to, but everyone was warm, friendly, and welcoming.
Good vibes all throughout, no notes.

Also, I enjoyed writing this field report: it's a good exercise for me to synthesize things I've learned during the conference, and hopefully it's informative for non-attendees to get an inside look into these academic research events.
I admit I haven't been writing in this blog recently (although in general, I've written way more during the past two years), so this might be another way to fill-in those spaces during the year.


Hoping to write more field reports in the future!