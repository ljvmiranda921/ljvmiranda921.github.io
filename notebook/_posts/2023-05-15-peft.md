---
layout: post
type: post
title: "Study notes on parameter-efficient finetuning techniques"
date: 2023-05-15
category: notebook
comments: true
author: "LJ MIRANDA"
published: true
tags: [efficient nlp, nlp, peft, parameter efficient finetuning, gpt, llm, large language models]
header-img: /assets/png/langchain/header.png
description: |
    Traditional finetuning involves training the parameters of a large language
    model with a shallower domain-specific network. However, this approach
    requires a large compute budget unavailable to most organizations. In this blog
    post, I'll go through differrent parameter-efficient finetuning techniques I
    personally like.
excerpt: |
    Traditional finetuning involves training the parameters of a large language
    model with a shallower domain-specific network. However, this approach
    requires a large compute budget unavailable to most organizations. In this blog
    post, I'll go through differrent parameter-efficient finetuning techniques I
    personally like.
---

<span class="firstcharacter">F</span>inetuning is a way to adapt pretrained
language models to a specific task or domain. It requires attaching a task head
to the model and updating the weights of the entire network. However,
this process can put a strain on one's compute budget. This becomes more true as
language models get larger and larger in every release.

In this blog post, I want to share my notes on parameter-efficient finetuning
techniques (PEFT). They are a collection of techniques that allow domain
adaptation at a lower compute cost. This is not a literature review; I will only
discuss methods I personally like. For each PEFT, I will talk about its
overview, related works, and high-level implementation.

## Finetuning is the status quo for domain adaptation, but it's inefficient

<!--

## There are efficient ways to adapt pretrained models


### Adapters - 


### Prompt tuning

### LoRA

-->

<!-- adapter networks -->


<!-- prefix tuning -->


<!-- mixture of experts -->