---
layout: post
type: post
title: "Study notes on parameter-efficient finetuning techniques"
date: 2023-05-15
category: notebook
comments: true
author: "LJ MIRANDA"
published: true
tags: [efficient nlp, nlp, peft, parameter efficient finetuning, gpt, llm, large language models]
header-img: /assets/png/langchain/header.png
description: |
    Traditional finetuning involves training the parameters of a large language
    model with a shallower domain-specific network. However, this approach
    requires a large compute budget unavailable to most organizations. In this blog
    post, I'll go through differrent parameter-efficient finetuning techniques I
    personally like.
excerpt: |
    Traditional finetuning involves training the parameters of a large language
    model with a shallower domain-specific network. However, this approach
    requires a large compute budget unavailable to most organizations. In this blog
    post, I'll go through differrent parameter-efficient finetuning techniques I
    personally like.
---

<span class="firstcharacter">F</span>inetuning is a way to adapt pretrained
language models to a specific task or domain. It requires attaching a task head
to the model and updating the weights of the entire network. However,
this process can put a strain on one's compute budget. This becomes more true as
language models get larger and larger in every release.

In this blog post, I want to share my notes on **parameter-efficient finetuning
techniques (PEFT).** They are a collection of techniques that allow domain
adaptation at a lower compute cost. This is not a literature review; I will only
discuss methods I personally like. For each PEFT, I will talk about its
overview, related works, and high-level implementation.

## Finetuning is the de facto domain adaptation technique, but it's inefficient

To recap, pretrained language models contain contextualized word representations
that capture the meaning of each token and its context within the text. By
themselves, they're already useful. However, language models have enjoyed
greater versatility and state-of-the-art performance because of finetuning
([Howard and Ruder, 2018](#howard2018ulmfit)).

<!--

- To recap, pretrained language models contain contextualized word representations that capture the meaning of each token and its context within the text.
- By themselves, they're already useful. However, language models have enjoyed greater versatility because of finetuning. 


- Pretrained language models have enjoyed greater versatility because of finetuning. 
- Context-sensitive vectors 


-->

<!--

## There are efficient ways to adapt pretrained models


### Adapters - 

### Prompt tuning

### LoRA

-->

<!-- adapter networks -->


<!-- prefix tuning -->


<!-- mixture of experts -->

## References

- <a id="howard2018ulmfit">Jeremy Howard and Sebastian Ruder</a>. 2018. Universal Language Model Fine-tuning for Text Classification. In *Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)*, pages 328â€“339, Melbourne, Australia. Association for Computational Linguistics.