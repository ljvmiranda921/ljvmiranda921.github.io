---
layout: post
type: post
title: "Not all NER datasets are created equal"
date: 2022-03-15
category: notebook
comments: true
author: "LJ MIRANDA"
published: true
tags: [nlp, span categorization, spacy, spans, machine learning, natural language processing, linguistics]
description: |
    Named-entity recognition (NER) datasets come in different shapes and sizes.
    This structure also contributes to how well machine learning techniques
    perform on said task. In this blogpost, we'll characterize a few NER
    datasets, and examine how its form affects its difficulty.
excerpt: |
    Named-entity recognition (NER) datasets come in different shapes and sizes.
    This structure also contributes to how well machine learning techniques
    perform on said task. In this blogpost, we'll characterize a few NER
    datasets, and examine how its form affects its difficulty.
---

<!--

- What is NER
    - NER datasets in the wild
- Introduce Papay et al's work: introduce 4 span characteristics
- Introduce the datasets we'll use
    - Standard NER: OntoNotes, ConLL
    - Quotation detection: RIQUA
    - Nested NER: ACE2004, ACE2005, GENIA
    - A few domain-specific datasets: EBM-NLP
-->

