---
layout: post
type: post
title: "Introducing FilBench: An LLM Evaluation Suite for Filipino"
date: 2025-08-21
category: projects
comments: true
author: "LJ MIRANDA"
published: true
tags:
  [
    nlp,
    language technology,
    natural language processing,
    tagalog,
    low resource,
    llm,
    machine learning,
  ]
description: |
  This Buwan ng Wika (National Language Month), I'm proud to introduce FilBench, a big step forward in Filipino NLP evaluation.
  Read to learn more!
excerpt: |
  This Buwan ng Wika (National Language Month), I'm proud to introduce FilBench, a big step forward in Filipino NLP evaluation.
  Read to learn more!
---

<span class="firstcharacter">A</span>t the end of 2024, I wrote about my [desiderata for Filipino NLP](/notebook/2024/12/17/filipino-llm/).
One of which was **evaluation**.
I said that most of "how we measure LLM capabilities in Filipino are anecdotal: we post a screenshot of ChatGPT writing in Filipino and claim that it already has that capability&mdash;we need a systematic approach to evaluating these models."
Fast forward to today, I'm happy that we are now inching towards systematic evaluations for Filipino.

Without further ado, I introduce **FilBench**, an LLM Evaluation Suite for Filipino!

<!-- Put placeholder for now until we open-source the leaderboard -->
<iframe
	src="https://mteb-leaderboard.hf.space"
	frameborder="0"
	width="700"
	height="450"
></iframe>

&nbsp;

## What is FilBench?

<img src="/assets/png/filbench/filbench_main.svg" align="right" height="500">

FilBench is a (1) **benchmark** to test LLM capabilities on Filipino, and a (2) **leaderboard** to track the progress of LLM development for Philippine languages.
When building FilBench, I imagine two types of audiences:

- The **multilingual NLP research scientist** who wants to test whether their new language model generalizes to other languages.
  FilBench aims to provide a robust and comprehensive evaluation suite for Filipino tasks and use-cases.

- The **language model developer** who wants to know which language model fits best for the application their building.
  The FilBench leaderboard provides a detailed breakdown of a model's capabilities, and analyses of the parameter- and cost-efficiency of such models.

When building FilBench, we took stock of what the Philippine NLP research community are evaluating pre-ChatGPT language models upon.
Although they are good at understanding language system capabilities, they are ill-posed for current LLM evaluation.
We then curated these datasets into four main categories: Cultural Knowledge, Classical NLP, Reading Comprehension, and Generation.

## On Building FilBench

One thing that's really exciting about building FilBench is that I'm like assembling the Avengers of Filipino NLP.
It actually started with just the three of us&mdash; [Ely](https://www.linkedin.com/in/elyanahaco2000/), [Conner](https://www.linkedin.com/in/connermanuel/), and I&mdash; working on the [Data Is Better Together annotation project](https://github.com/huggingface/data-is-better-together) from HuggingFace.
I've met them separately through other projects like [SEACrowd](https://seacrowd.github.io/) and earlier correspondences.
Then, we've onboarded [Joseph](https://www.josephimperial.com/) and [Blaise](https://blaisecruz.com/), who have been working on Filipino NLP since I entered the field.
We're just five right now, but hopefully tomorrow there'll be more of us.

There's an appeal to grassroots projects like this, given that all of us are volunteers spending our free time on FilBench.
All of us automatically pass the "will-they-care-about-this-project" bar right away, which makes collaboration smoother.
There are hurdles too, such as scrounging up compute for running evals, or finding the right time across 4-5 timezones.
But the scrappiness of the group is energizing, and it allowed us to iterate and build FilBench despite little to no resources.

## What's next

I have a lot of new ideas for FilBench v2.
However, I want to maintain my key priority for developing FilBench, i.e., to improve the scope of Philippine languages in our benchmark.
If we can cover at least the major regional languages spoken in the Philippines, then I can say that FilBench is successful.
If you have some ideas on how we can expand FilBench for Ilokano, Hiligaynon, and Cebuano, then please [reach out](mailto:ljvmiranda@gmail.com)!

- **Paper**:
- **Leaderboard**

&nbsp;

---

&nbsp;

### Postscript: does it make sense to train Filipino LLMs?

It seems that the logical next step is to train language models that will optimize performance on FilBench.
However, I believe we must exercise caution in order to avoid spending unnecessary time and resources on something that GPT-4 or future advanced models could acoomplish.

Ideally, I want us to avoid _incremental_ post-training efforts that follow the standard recipe with just more Philippine language data.
While papers will certainly be written on which types of Philippine langauge data work best for FilBench, I doubt there's a substantial market for Filipino-centric LLMs, given that many Filipinos speak proficient English.

In my opinion, building LLMs for Filipino makes sense under three conditions:

- **Low-cost models that work on cheap phones without internet connection.** This could include models that understand Filipino text-speak or parameter-efficient models optimized for low-end devices.

- **Domain-specific applications where cultural context is critical.** This could include models that cater to legal documents within the Philippine justice system, educational tools, BPO and call centers, and healthcare communication to name a few. One can definitely build a startup on this, and one notable example is [Anycase.ai](https://anycase.ai/).

- **As a demonstration of what a Philippine AI Lab can do.** Training a Filipino-centric LLM as a demonstration for capacity-building and cultivating homegrown talent in the Philippines would be valuable. In this case, the value is not in the final model articfact, but in the infrastructure (talent and GPU) developed to build it. The final post-train model might be incremental, but the point is we now have the infrastructure to iterate.

Working on any of these three domains can help improve our national competitiveness in AI.
By focusing on these strategic areas, the country can build genuine AI capabilities that serve both local needs and contribute to the global AI ecosystem.
